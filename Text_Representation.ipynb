{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd63bad-9115-4657-abf4-9bedda5c7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd49f72-6e33-4700-9e99-3f2fc8deb66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecdbf5d7-0447-4e5d-914e-dd8ae09276a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00a8e227-b80a-44c6-b25d-059f39192c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f47d66d8-c1d2-4b54-a13f-882e772d381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def remove_html(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4befa7e-b466-441c-99fa-b0ad708f1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a51a9a00-06a2-4438-9b2b-feaebb2f5edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df1a2b89-1c7f-4c4e-9493-6c66df08a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "exclude = string.punctuation\n",
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ddb2bb3-40d6-4a02-927c-d05e9380141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ee4dd3-a1b1-4bf0-9f7e-e0a9b6accae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production the filming tech...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically theres a family where a little boy j...  negative\n",
       "4  petter matteis love in the time of money is a ...  positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2c2b10a-f1b3-4da8-84b5-b73e35c5ad0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production the filming tech...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically theres a family where a little boy j...\n",
       "4        petter matteis love in the time of money is a ...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    im going to have to disagree with the previous...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abd21ac6-a7d7-4af0-bf23-8111ead8c814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\joshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\joshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from textblob) (3.9.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\joshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.9->textblob) (2025.11.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\joshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.9->textblob) (1.5.3)\n",
      "Requirement already satisfied: click in c:\\users\\joshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.9->textblob) (8.3.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\joshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\joshi\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\joshi\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8c71924-ffcf-46e6-8734-23cb08d89c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from textblob) (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from nltk>=3.9->textblob) (8.3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from nltk>=3.9->textblob) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from nltk>=3.9->textblob) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a8df289-6fc0-47da-9df4-53b56b345597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: symspellpy in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (6.9.0)\n",
      "Requirement already satisfied: editdistpy>=0.1.3 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from symspellpy) (0.1.6)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install symspellpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3b06077e-39a1-4cd0-a7b9-68530fee1d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\joshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d59ad4dc-2fd2-4931-baf7-1697d6275b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "STOP_WORDS = set(stopwords.words('english'))  \n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join(\n",
    "        word for word in str(text).split()\n",
    "        if word not in STOP_WORDS\n",
    "    )\n",
    "\n",
    "df['review'] = df['review'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f53c337-741b-4254-9114-644d31e03d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewers mentioned watching 1 oz episode ...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  thought wonderful way spend time hot summer we...  positive\n",
       "3  basically theres family little boy jake thinks...  negative\n",
       "4  petter matteis love time money visually stunni...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "379f4b44-2de6-48c6-a96f-85873e050a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.11-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.15-cp310-cp310-win_amd64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.13-cp310-cp310-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.12-cp310-cp310-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.10-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.2-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy)\n",
      "  Downloading weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer_slim-0.21.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from spacy) (2.32.5)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from spacy) (57.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from spacy) (25.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.41.5-cp310-cp310-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-extensions>=4.14.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.3-cp310-cp310-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joshi\\envs\\ml-env\\lib\\site-packages (from jinja2->spacy) (3.0.3)\n",
      "Downloading spacy-3.8.11-cp310-cp310-win_amd64.whl (15.3 MB)\n",
      "   ---------------------------------------- 0.0/15.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/15.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/15.3 MB 932.9 kB/s eta 0:00:16\n",
      "   -- ------------------------------------- 0.8/15.3 MB 932.9 kB/s eta 0:00:16\n",
      "   -- ------------------------------------- 0.8/15.3 MB 932.9 kB/s eta 0:00:16\n",
      "   -- ------------------------------------- 1.0/15.3 MB 932.9 kB/s eta 0:00:16\n",
      "   -- ------------------------------------- 1.0/15.3 MB 932.9 kB/s eta 0:00:16\n",
      "   --- ------------------------------------ 1.3/15.3 MB 745.8 kB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 1.6/15.3 MB 847.3 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.6/15.3 MB 847.3 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.8/15.3 MB 846.1 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 2.1/15.3 MB 870.1 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 2.1/15.3 MB 870.1 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 2.1/15.3 MB 870.1 kB/s eta 0:00:16\n",
      "   ------ --------------------------------- 2.4/15.3 MB 767.1 kB/s eta 0:00:17\n",
      "   ------ --------------------------------- 2.4/15.3 MB 767.1 kB/s eta 0:00:17\n",
      "   ------ --------------------------------- 2.6/15.3 MB 758.9 kB/s eta 0:00:17\n",
      "   ------ --------------------------------- 2.6/15.3 MB 758.9 kB/s eta 0:00:17\n",
      "   ------ --------------------------------- 2.6/15.3 MB 758.9 kB/s eta 0:00:17\n",
      "   ------- -------------------------------- 2.9/15.3 MB 696.3 kB/s eta 0:00:18\n",
      "   -------- ------------------------------- 3.1/15.3 MB 712.5 kB/s eta 0:00:18\n",
      "   -------- ------------------------------- 3.4/15.3 MB 743.0 kB/s eta 0:00:17\n",
      "   -------- ------------------------------- 3.4/15.3 MB 743.0 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.7/15.3 MB 736.8 kB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 3.9/15.3 MB 738.7 kB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 3.9/15.3 MB 738.7 kB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 3.9/15.3 MB 738.7 kB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 4.2/15.3 MB 721.1 kB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 4.5/15.3 MB 741.6 kB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 4.5/15.3 MB 741.6 kB/s eta 0:00:15\n",
      "   ------------ --------------------------- 4.7/15.3 MB 735.1 kB/s eta 0:00:15\n",
      "   ------------ --------------------------- 5.0/15.3 MB 758.9 kB/s eta 0:00:14\n",
      "   ------------ --------------------------- 5.0/15.3 MB 758.9 kB/s eta 0:00:14\n",
      "   ------------- -------------------------- 5.2/15.3 MB 750.1 kB/s eta 0:00:14\n",
      "   --------------- ------------------------ 5.8/15.3 MB 781.2 kB/s eta 0:00:13\n",
      "   --------------- ------------------------ 6.0/15.3 MB 802.4 kB/s eta 0:00:12\n",
      "   --------------- ------------------------ 6.0/15.3 MB 802.4 kB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 6.6/15.3 MB 825.1 kB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 6.8/15.3 MB 842.3 kB/s eta 0:00:11\n",
      "   ------------------ --------------------- 7.1/15.3 MB 862.1 kB/s eta 0:00:10\n",
      "   ------------------- -------------------- 7.3/15.3 MB 866.1 kB/s eta 0:00:10\n",
      "   ------------------- -------------------- 7.3/15.3 MB 866.1 kB/s eta 0:00:10\n",
      "   ------------------- -------------------- 7.6/15.3 MB 860.4 kB/s eta 0:00:10\n",
      "   -------------------- ------------------- 7.9/15.3 MB 867.3 kB/s eta 0:00:09\n",
      "   --------------------- ------------------ 8.4/15.3 MB 893.7 kB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 8.7/15.3 MB 897.8 kB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 8.9/15.3 MB 907.6 kB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 9.2/15.3 MB 921.5 kB/s eta 0:00:07\n",
      "   ------------------------ --------------- 9.4/15.3 MB 933.6 kB/s eta 0:00:07\n",
      "   ------------------------- -------------- 9.7/15.3 MB 939.3 kB/s eta 0:00:07\n",
      "   ------------------------- -------------- 10.0/15.3 MB 952.1 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 10.0/15.3 MB 952.1 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 10.2/15.3 MB 939.0 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 10.2/15.3 MB 939.0 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 10.2/15.3 MB 939.0 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 10.5/15.3 MB 895.1 kB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 10.7/15.3 MB 902.0 kB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 10.7/15.3 MB 902.0 kB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 11.0/15.3 MB 896.9 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 11.0/15.3 MB 896.9 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 11.3/15.3 MB 894.3 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 11.5/15.3 MB 892.8 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 11.5/15.3 MB 892.8 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 11.8/15.3 MB 891.6 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 12.1/15.3 MB 896.7 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 12.1/15.3 MB 896.7 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 12.6/15.3 MB 901.2 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 12.6/15.3 MB 901.2 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 12.6/15.3 MB 901.2 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 12.8/15.3 MB 889.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 13.1/15.3 MB 892.6 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 13.1/15.3 MB 892.6 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 13.6/15.3 MB 895.9 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.6/15.3 MB 895.9 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.9/15.3 MB 886.6 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.9/15.3 MB 886.6 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.9/15.3 MB 886.6 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 14.2/15.3 MB 877.0 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 14.2/15.3 MB 877.0 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 14.2/15.3 MB 877.0 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 14.4/15.3 MB 862.0 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 14.7/15.3 MB 860.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.7/15.3 MB 860.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.3 MB 858.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.3 MB 858.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.3 MB 858.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  15.2/15.3 MB 843.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.3/15.3 MB 835.2 kB/s  0:00:18\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.13-cp310-cp310-win_amd64.whl (40 kB)\n",
      "Downloading murmurhash-1.0.15-cp310-cp310-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.12-cp310-cp310-win_amd64.whl (117 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 419.4 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 419.4 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 0.8/2.0 MB 568.6 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 1.0/2.0 MB 637.3 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.0/2.0 MB 637.3 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.3/2.0 MB 651.7 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.6/2.0 MB 682.0 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 682.0 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 682.0 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 621.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 633.2 kB/s  0:00:03\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.2-cp310-cp310-win_amd64.whl (654 kB)\n",
      "   ---------------------------------------- 0.0/654.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/654.0 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/654.0 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/654.0 kB ? eta -:--:--\n",
      "   ------------------------------ ------- 524.3/654.0 kB 837.5 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 524.3/654.0 kB 837.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 654.0/654.0 kB 611.4 kB/s  0:00:01\n",
      "Downloading thinc-8.3.10-cp310-cp310-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 730.2 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 838.9 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 838.9 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 838.9 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 699.0 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 699.0 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 699.0 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 588.8 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 588.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 603.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 640.0 kB/s  0:00:02\n",
      "Downloading blis-1.3.3-cp310-cp310-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.2 MB 419.4 kB/s eta 0:00:14\n",
      "   ------ --------------------------------- 1.0/6.2 MB 811.6 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.3/6.2 MB 932.1 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.1/6.2 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.1/6.2 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 2.9/6.2 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 3.1/6.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 3.4/6.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 3.7/6.2 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 4.2/6.2 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.7/6.2 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 5.2/6.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.8/6.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.8/6.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 1.3 MB/s  0:00:05\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading typer_slim-0.21.0-py3-none-any.whl (47 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: wasabi, typing-extensions, spacy-loggers, spacy-legacy, smart-open, murmurhash, cymem, catalogue, blis, annotated-types, typing-inspection, typer-slim, srsly, pydantic-core, preshed, cloudpathlib, pydantic, confection, weasel, thinc, spacy\n",
      "\n",
      "  Attempting uninstall: typing-extensions\n",
      "\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "   - --------------------------------------  1/21 [typing-extensions]\n",
      "   ------- --------------------------------  4/21 [smart-open]\n",
      "   ------- --------------------------------  4/21 [smart-open]\n",
      "   --------- ------------------------------  5/21 [murmurhash]\n",
      "   ------------- --------------------------  7/21 [catalogue]\n",
      "   --------------- ------------------------  8/21 [blis]\n",
      "   -------------------- ------------------- 11/21 [typer-slim]\n",
      "   -------------------- ------------------- 11/21 [typer-slim]\n",
      "   ---------------------- ----------------- 12/21 [srsly]\n",
      "   ---------------------- ----------------- 12/21 [srsly]\n",
      "   ---------------------- ----------------- 12/21 [srsly]\n",
      "   ---------------------- ----------------- 12/21 [srsly]\n",
      "   -------------------------- ------------- 14/21 [preshed]\n",
      "   ---------------------------- ----------- 15/21 [cloudpathlib]\n",
      "   ---------------------------- ----------- 15/21 [cloudpathlib]\n",
      "   ------------------------------ --------- 16/21 [pydantic]\n",
      "   ------------------------------ --------- 16/21 [pydantic]\n",
      "   ------------------------------ --------- 16/21 [pydantic]\n",
      "   ------------------------------ --------- 16/21 [pydantic]\n",
      "   -------------------------------- ------- 17/21 [confection]\n",
      "   ---------------------------------- ----- 18/21 [weasel]\n",
      "   ---------------------------------- ----- 18/21 [weasel]\n",
      "   ------------------------------------ --- 19/21 [thinc]\n",
      "   ------------------------------------ --- 19/21 [thinc]\n",
      "   ------------------------------------ --- 19/21 [thinc]\n",
      "   ------------------------------------ --- 19/21 [thinc]\n",
      "   ------------------------------------ --- 19/21 [thinc]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   -------------------------------------- - 20/21 [spacy]\n",
      "   ---------------------------------------- 21/21 [spacy]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 blis-1.3.3 catalogue-2.0.10 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 murmurhash-1.0.15 preshed-3.0.12 pydantic-2.12.5 pydantic-core-2.41.5 smart-open-7.5.0 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 thinc-8.3.10 typer-slim-0.21.0 typing-extensions-4.15.0 typing-inspection-0.4.2 wasabi-1.1.3 weasel-0.4.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8dcc5dcd-7411-443a-a786-49162d727226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     -- ------------------------------------ 0.8/12.8 MB 588.4 kB/s eta 0:00:21\n",
      "     -- ------------------------------------ 0.8/12.8 MB 588.4 kB/s eta 0:00:21\n",
      "     -- ------------------------------------ 0.8/12.8 MB 588.4 kB/s eta 0:00:21\n",
      "     -- ------------------------------------ 0.8/12.8 MB 588.4 kB/s eta 0:00:21\n",
      "     --- ----------------------------------- 1.0/12.8 MB 498.4 kB/s eta 0:00:24\n",
      "     --- ----------------------------------- 1.3/12.8 MB 578.4 kB/s eta 0:00:20\n",
      "     ---- ---------------------------------- 1.6/12.8 MB 630.8 kB/s eta 0:00:18\n",
      "     ---- ---------------------------------- 1.6/12.8 MB 630.8 kB/s eta 0:00:18\n",
      "     ----- --------------------------------- 1.8/12.8 MB 653.7 kB/s eta 0:00:17\n",
      "     ----- --------------------------------- 1.8/12.8 MB 653.7 kB/s eta 0:00:17\n",
      "     ------- ------------------------------- 2.4/12.8 MB 699.0 kB/s eta 0:00:15\n",
      "     ------- ------------------------------- 2.4/12.8 MB 699.0 kB/s eta 0:00:15\n",
      "     ------- ------------------------------- 2.6/12.8 MB 729.5 kB/s eta 0:00:14\n",
      "     -------- ------------------------------ 2.9/12.8 MB 723.2 kB/s eta 0:00:14\n",
      "     -------- ------------------------------ 2.9/12.8 MB 723.2 kB/s eta 0:00:14\n",
      "     ---------- ---------------------------- 3.4/12.8 MB 780.4 kB/s eta 0:00:13\n",
      "     ---------- ---------------------------- 3.4/12.8 MB 780.4 kB/s eta 0:00:13\n",
      "     ----------- --------------------------- 3.7/12.8 MB 765.3 kB/s eta 0:00:12\n",
      "     ----------- --------------------------- 3.7/12.8 MB 765.3 kB/s eta 0:00:12\n",
      "     ----------- --------------------------- 3.9/12.8 MB 767.6 kB/s eta 0:00:12\n",
      "     ------------ -------------------------- 4.2/12.8 MB 789.0 kB/s eta 0:00:11\n",
      "     ------------ -------------------------- 4.2/12.8 MB 789.0 kB/s eta 0:00:11\n",
      "     ------------- ------------------------- 4.5/12.8 MB 775.9 kB/s eta 0:00:11\n",
      "     -------------- ------------------------ 4.7/12.8 MB 801.1 kB/s eta 0:00:11\n",
      "     --------------- ----------------------- 5.0/12.8 MB 809.6 kB/s eta 0:00:10\n",
      "     --------------- ----------------------- 5.0/12.8 MB 809.6 kB/s eta 0:00:10\n",
      "     --------------- ----------------------- 5.2/12.8 MB 811.1 kB/s eta 0:00:10\n",
      "     ---------------- ---------------------- 5.5/12.8 MB 806.6 kB/s eta 0:00:10\n",
      "     ---------------- ---------------------- 5.5/12.8 MB 806.6 kB/s eta 0:00:10\n",
      "     ----------------- --------------------- 5.8/12.8 MB 809.9 kB/s eta 0:00:09\n",
      "     ------------------ -------------------- 6.0/12.8 MB 827.5 kB/s eta 0:00:09\n",
      "     ------------------- ------------------- 6.3/12.8 MB 833.5 kB/s eta 0:00:08\n",
      "     ------------------- ------------------- 6.3/12.8 MB 833.5 kB/s eta 0:00:08\n",
      "     ------------------- ------------------- 6.6/12.8 MB 830.2 kB/s eta 0:00:08\n",
      "     ------------------- ------------------- 6.6/12.8 MB 830.2 kB/s eta 0:00:08\n",
      "     -------------------- ------------------ 6.8/12.8 MB 816.0 kB/s eta 0:00:08\n",
      "     -------------------- ------------------ 6.8/12.8 MB 816.0 kB/s eta 0:00:08\n",
      "     -------------------- ------------------ 6.8/12.8 MB 816.0 kB/s eta 0:00:08\n",
      "     --------------------- ----------------- 7.1/12.8 MB 791.7 kB/s eta 0:00:08\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 803.1 kB/s eta 0:00:07\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 803.1 kB/s eta 0:00:07\n",
      "     ----------------------- --------------- 7.6/12.8 MB 797.6 kB/s eta 0:00:07\n",
      "     ----------------------- --------------- 7.9/12.8 MB 805.5 kB/s eta 0:00:07\n",
      "     ------------------------ -------------- 8.1/12.8 MB 806.6 kB/s eta 0:00:06\n",
      "     ------------------------ -------------- 8.1/12.8 MB 806.6 kB/s eta 0:00:06\n",
      "     ------------------------ -------------- 8.1/12.8 MB 806.6 kB/s eta 0:00:06\n",
      "     ------------------------- ------------- 8.4/12.8 MB 792.8 kB/s eta 0:00:06\n",
      "     ------------------------- ------------- 8.4/12.8 MB 792.8 kB/s eta 0:00:06\n",
      "     -------------------------- ------------ 8.7/12.8 MB 779.2 kB/s eta 0:00:06\n",
      "     --------------------------- ----------- 8.9/12.8 MB 785.3 kB/s eta 0:00:05\n",
      "     --------------------------- ----------- 9.2/12.8 MB 792.3 kB/s eta 0:00:05\n",
      "     --------------------------- ----------- 9.2/12.8 MB 792.3 kB/s eta 0:00:05\n",
      "     ---------------------------- ---------- 9.4/12.8 MB 790.3 kB/s eta 0:00:05\n",
      "     ---------------------------- ---------- 9.4/12.8 MB 790.3 kB/s eta 0:00:05\n",
      "     ----------------------------- --------- 9.7/12.8 MB 783.4 kB/s eta 0:00:04\n",
      "     ----------------------------- -------- 10.0/12.8 MB 788.8 kB/s eta 0:00:04\n",
      "     ----------------------------- -------- 10.0/12.8 MB 788.8 kB/s eta 0:00:04\n",
      "     ------------------------------ ------- 10.2/12.8 MB 794.9 kB/s eta 0:00:04\n",
      "     ------------------------------- ------ 10.5/12.8 MB 797.9 kB/s eta 0:00:03\n",
      "     -------------------------------- ----- 11.0/12.8 MB 821.8 kB/s eta 0:00:03\n",
      "     --------------------------------- ---- 11.3/12.8 MB 830.9 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.5/12.8 MB 836.0 kB/s eta 0:00:02\n",
      "     ---------------------------------- --- 11.5/12.8 MB 836.0 kB/s eta 0:00:02\n",
      "     ----------------------------------- -- 11.8/12.8 MB 834.1 kB/s eta 0:00:02\n",
      "     ----------------------------------- -- 12.1/12.8 MB 838.8 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 12.3/12.8 MB 844.4 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 861.4 kB/s  0:00:15\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "600b3800-fa57-4e05-a95e-6a155e77bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load only tokenizer (disable heavy components)\n",
    "nlp = spacy.load(\n",
    "    \"en_core_web_sm\",\n",
    "    disable=[\"parser\", \"ner\", \"tagger\", \"lemmatizer\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b9e73c-5e46-4795-81d9-6eb350a69da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenize(text):\n",
    "    doc = nlp(str(text))\n",
    "    return [token.text for token in doc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8ce9fd1-dddf-4b4f-8315-48c44c44efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = [\n",
    "    [\n",
    "        token.text.lower()\n",
    "        for token in doc\n",
    "        if not token.is_punct and not token.is_space\n",
    "    ]\n",
    "    for doc in nlp.pipe(df['review'].astype(str), batch_size=1000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b40d1863-a3aa-47ab-9cbe-f9dfb3968332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[one, reviewers, mentioned, watching, 1, oz, e...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, reviewers, mentioned, watching, 1, oz, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[basically, there, s, family, little, boy, jak...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, there, s, family, little, boy, jak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  [one, reviewers, mentioned, watching, 1, oz, e...  positive   \n",
       "1  [wonderful, little, production, filming, techn...  positive   \n",
       "2  [thought, wonderful, way, spend, time, hot, su...  positive   \n",
       "3  [basically, there, s, family, little, boy, jak...  negative   \n",
       "4  [petter, matteis, love, time, money, visually,...  positive   \n",
       "\n",
       "                                              tokens  \n",
       "0  [one, reviewers, mentioned, watching, 1, oz, e...  \n",
       "1  [wonderful, little, production, filming, techn...  \n",
       "2  [thought, wonderful, way, spend, time, hot, su...  \n",
       "3  [basically, there, s, family, little, boy, jak...  \n",
       "4  [petter, matteis, love, time, money, visually,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa028756-607c-42af-a740-cb2e9be54971",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65f38335-d95a-4a41-9ed7-db42ed584f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[one, reviewers, mentioned, watching, 1, oz, e...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[basically, there, s, family, little, boy, jak...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  [one, reviewers, mentioned, watching, 1, oz, e...  positive\n",
       "1  [wonderful, little, production, filming, techn...  positive\n",
       "2  [thought, wonderful, way, spend, time, hot, su...  positive\n",
       "3  [basically, there, s, family, little, boy, jak...  negative\n",
       "4  [petter, matteis, love, time, money, visually,...  positive"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8c88238-1396-4d81-8e64-4796a6efb918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cd57e8c-8c0f-436c-98e1-5bb5017ffc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "df['review'] = df['review'].apply(lambda tokens : [ps.stem(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d3ce27a-f5c0-433e-a001-172864aaf421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[one, review, mention, watch, 1, oz, episod, y...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[wonder, littl, product, film, techniqu, unass...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[basic, there, s, famili, littl, boy, jake, th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[petter, mattei, love, time, money, visual, st...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  [one, review, mention, watch, 1, oz, episod, y...  positive\n",
       "1  [wonder, littl, product, film, techniqu, unass...  positive\n",
       "2  [thought, wonder, way, spend, time, hot, summe...  positive\n",
       "3  [basic, there, s, famili, littl, boy, jake, th...  negative\n",
       "4  [petter, mattei, love, time, money, visual, st...  positive"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c9ec350-16a9-42fc-b7f0-6b9a37d3095d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df['review'].astype(str).tolist()\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c42f9b2d-9e94-4915-b630-22272a70f4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size :  10\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set()\n",
    "for tokens in df['review']:\n",
    "    vocabulary.update(tokens)\n",
    "vocabulary_size = len(vocabulary)\n",
    "print('Vocabulary size : ',vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38abb25-1f65-4007-a488-fdf7b8064f16",
   "metadata": {},
   "source": [
    "## One Hot Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1801aff4-1371-4d44-b3be-f490ac13df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "onehot_vectorizer = CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "onehot_matrix = onehot_vectorizer.fit_transform(df['review'])\n",
    "\n",
    "onehot_df = pd.DataFrame(\n",
    "    onehot_matrix.toarray(),\n",
    "    columns=onehot_vectorizer.get_feature_names_out()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a222240-25ac-463f-8062-c5fe2d299cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>do</th>\n",
       "      <th>enough</th>\n",
       "      <th>go</th>\n",
       "      <th>nothing</th>\n",
       "      <th>old</th>\n",
       "      <th>something</th>\n",
       "      <th>them</th>\n",
       "      <th>will</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      do  enough  go  nothing  old  something  them  will  you\n",
       "0  1   0       0   0        0    0          0     1     1    0\n",
       "1  1   0       0   0        0    0          0     0     0    0\n",
       "2  1   0       0   0        0    0          0     0     0    0\n",
       "3  1   0       0   0        0    0          0     0     0    0\n",
       "4  1   0       0   0        0    0          0     0     0    0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c74e5f5-1685-4fc3-8614-9854029452e6",
   "metadata": {},
   "source": [
    "## Bag of Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90da2dda-943b-4b4c-bbca-410a9dc25170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_vectorizer = CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None\n",
    ")\n",
    "bow_matrix = bow_vectorizer.fit_transform(df['review'])\n",
    "bow_df = pd.DataFrame(\n",
    "    bow_matrix.toarray(),\n",
    "    columns = bow_vectorizer.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6498989c-36f0-4919-897b-47416deb8ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>do</th>\n",
       "      <th>enough</th>\n",
       "      <th>go</th>\n",
       "      <th>nothing</th>\n",
       "      <th>old</th>\n",
       "      <th>something</th>\n",
       "      <th>them</th>\n",
       "      <th>will</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        do  enough  go  nothing  old  something  them  will  you\n",
       "0  170   0       0   0        0    0          0     1     3    0\n",
       "1   84   0       0   0        0    0          0     0     0    0\n",
       "2   88   0       0   0        0    0          0     0     0    0\n",
       "3   70   0       0   0        0    0          0     0     0    0\n",
       "4  125   0       0   0        0    0          0     0     0    0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10276dbc-f71c-4de9-afb0-376314f26802",
   "metadata": {},
   "source": [
    "## N - grams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9957cb9f-b429-4873-b80e-d29cd3fb3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "# FIT on the SAME object\n",
    "ngram_matrix = ngram_vectorizer.fit_transform(df['review'])\n",
    "\n",
    "ngram_df = pd.DataFrame(\n",
    "    ngram_matrix.toarray(),\n",
    "    columns=ngram_vectorizer.get_feature_names_out()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04246d1b-6413-467a-b13b-df0a2e58983f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>do</th>\n",
       "      <th>enough</th>\n",
       "      <th>go</th>\n",
       "      <th>nothing</th>\n",
       "      <th>old</th>\n",
       "      <th>something</th>\n",
       "      <th>them</th>\n",
       "      <th>will</th>\n",
       "      <th>...</th>\n",
       "      <th>old</th>\n",
       "      <th>old old</th>\n",
       "      <th>something</th>\n",
       "      <th>something</th>\n",
       "      <th>them</th>\n",
       "      <th>them</th>\n",
       "      <th>will</th>\n",
       "      <th>will</th>\n",
       "      <th>you</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              do   enough   go   nothing   old   something   them   will  ...  \\\n",
       "0  170  165    0        0    0         0     0           0      1      3  ...   \n",
       "1   84   83    0        0    0         0     0           0      0      0  ...   \n",
       "2   88   87    0        0    0         0     0           0      0      0  ...   \n",
       "3   70   69    0        0    0         0     0           0      0      0  ...   \n",
       "4  125  124    0        0    0         0     0           0      0      0  ...   \n",
       "\n",
       "   old   old old  something  something   them  them   will  will   you  you   \n",
       "0     0        0          0           0     1      1     3      3    0     0  \n",
       "1     0        0          0           0     0      0     0      0    0     0  \n",
       "2     0        0          0           0     0      0     0      0    0     0  \n",
       "3     0        0          0           0     0      0     0      0    0     0  \n",
       "4     0        0          0           0     0      0     0      0    0     0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a63ba2-f040-4e32-905e-1756bb5027db",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d7717da-9a03-401f-b097-20d3f1be8d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    tokenizer = lambda x : x,\n",
    "    preprocessor = lambda x : x,\n",
    "    token_pattern = None\n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['review'])\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns = tfidf_vectorizer.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbfa98df-c1f8-46e1-86be-b8eece754f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>do</th>\n",
       "      <th>enough</th>\n",
       "      <th>go</th>\n",
       "      <th>nothing</th>\n",
       "      <th>old</th>\n",
       "      <th>something</th>\n",
       "      <th>them</th>\n",
       "      <th>will</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038272</td>\n",
       "      <td>0.06874</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            do  enough   go  nothing  old  something      them     will  you\n",
       "0  0.9969  0.0     0.0  0.0      0.0  0.0        0.0  0.038272  0.06874  0.0\n",
       "1  1.0000  0.0     0.0  0.0      0.0  0.0        0.0  0.000000  0.00000  0.0\n",
       "2  1.0000  0.0     0.0  0.0      0.0  0.0        0.0  0.000000  0.00000  0.0\n",
       "3  1.0000  0.0     0.0  0.0      0.0  0.0        0.0  0.000000  0.00000  0.0\n",
       "4  1.0000  0.0     0.0  0.0      0.0  0.0        0.0  0.000000  0.00000  0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5ec2a-1472-4e14-b580-f8663038464e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4124891-19a0-4bb9-bdb0-7c5a5d9379cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80318153-3ee3-4acb-b8d9-38546249b4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8eb4c-d206-435d-9100-f61599388adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488263d0-1dd5-4b21-874e-18aa5b266e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd267fe0-783c-45cb-95ab-1b5c6d78b943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d42d1c-68df-426c-8075-a8fa86b50e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57c18f-9e50-4cc2-9288-ff9e3f75e344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b4261-40f1-419c-a6ad-141404e23319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6580820a-f2f0-4077-827d-fb92167d734b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92413a38-4e06-4e75-bd7e-0908c014a99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df808815-891c-457d-bc88-e8b876f68e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850acc0-030e-4e49-8a31-8002b34e1f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf74891-0c71-4e2e-a94e-3e88b5c18440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84cf03-37fc-4798-af53-2876afa81fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e2ed85-5971-4bd6-92aa-0b5d8a07fcb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00e139-9109-4857-8ed5-1d0a9b5f1f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9814737-8d12-4a48-836b-b50e94e7fc77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb600be-0762-456f-9cef-6bccfda2e155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9fab11-52d2-45ca-8c04-f113b1a28625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76810cdd-f38a-4bdb-94a3-c50447f7999a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92392f69-f4a4-4598-bf58-196c0f2e2af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b2b96b-2cba-40d6-a45f-ea58f99bf98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b82e12-46ba-487f-a2d8-a62f505aee5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd06bde-c2ed-4caa-9b3a-4d5bdbeef103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58003af-da87-4cbb-8039-4cc4066e5b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d75a6-4c25-4f41-9862-1e6d1336556d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b3e7d-68f9-466f-b4a5-91adf664474d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5839909-9890-47b6-8811-d486217059ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9855c37-60f1-4966-91a9-204b9e6871ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc4338-a513-4706-81f1-2a123939012d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec635f-a3db-4924-b77a-bfbb18672352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15d15c-f18d-4dae-9890-ba07f0efd90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e593f-7e01-4140-b1ec-cc65fa2d55ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfbae9-7529-4ac6-9d34-aa90e0108154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888501b9-d2de-4569-90f0-b08ebdce98bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e65fa40-761e-4add-98dc-9ed8302b8930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-env)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
